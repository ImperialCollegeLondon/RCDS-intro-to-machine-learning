{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary of machine learning terms\n",
    "\n",
    "Click on each section title to see the most relevant Wikipedia entry for that term.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"ai\" href=\"https://en.wikipedia.org/wiki/Artificial_intelligence\">artificial intelligence</a>\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"clustering\" href=\"https://en.wikipedia.org/wiki/Cluster_analysis\">clustering</a>\n",
    "Blah\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"deep_learning\" href=\"https://en.wikipedia.org/wiki/Deep_learning\">deep learning</a>\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"distance_metric\" href=\"https://en.wikipedia.org/wiki/Metric_(mathematics)\">distance metric</a>\n",
    "\n",
    "A distance metric provides a measure of how different two data points are. There are very many ways in which we can define \"difference\", and hence a variety of distance metrics are in common use in machine learning. A few examples:\n",
    "\n",
    "#### [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance)\n",
    "\n",
    "$d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{ \\sum_{i=1}^n (p_i-q_i)^2} = \\sqrt{ (p_1 - q_1)^2 + (p_2 - q_2)^2+\\cdots+(p_i - q_i)^2+\\cdots+(p_n - q_n)^2}$\n",
    "\n",
    "This just extends the intuitive concept of \"distance\" in 2D or 3D space to higher dimensions.\n",
    "\n",
    "#### [Manhattan distance](https://en.wikipedia.org/wiki/Taxicab_geometry)\n",
    "\n",
    "also know as the $l_1$ norm:\n",
    "\n",
    "$d(\\mathbf{p}, \\mathbf{q}) = \\sum_{i=1}^n |p_i-q_i|$\n",
    "\n",
    "This can be useful for distances between frequency distributions.\n",
    "\n",
    "#### [Hamming distance](https://en.wikipedia.org/wiki/Hamming_distance#History_and_applications)\n",
    "\n",
    "The Hamming distance between two equal-length strings of symbols is simply the number of positions at which the corresponding symbols are different.\n",
    "\n",
    "This could be a useful distance metric for clustering sequences related via mutations, for example viral DNA sequences.\n",
    "\n",
    "#### Other distances\n",
    "\n",
    "Other domain-specific distances may be useful for [unsupervised learning](#unsupervised_learning), even if they do not meet the formal definition of a metric. For example, in bioinformatics the BLAST E-value for a pair of protein sequences can be a useful distance measure for many types of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"feature\" href=\"https://en.wikipedia.org/wiki/Feature_(machine_learning)\">feature</a>\n",
    "Blah\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"function\"></a>function\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"k-means\"></a>k-means\n",
    "Blah\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"model\" href=\"https://en.wikipedia.org/wiki/Statistical_model\">model</a>\n",
    "Blah\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"loss_function\"></a>loss function\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"machine_learning\"></a>machine learning\n",
    "Blah\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"optimisation\"></a>optimisation\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"parameter\"></a>parameter\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"response\"></a>response\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"silhouette\"></a>[silhouette score](https://en.wikipedia.org/wiki/Silhouette_(clustering))\n",
    "\n",
    "After *[clusters](#clustering)* have been defined, the *silhouette score* for each element quantifies how similar that element is to the other elements in the same cluster, relative to the elements belonging to other clusters. This is calculated on a scale from -1 to +1, and requires us to choose a suitable *[distance metric](#distance_metric)*.\n",
    "\n",
    "By summing the silhouette scores for all elements, we can produce an overall score for the clustering, which can be compared to the scores obtained from other potential clustering solutions (for example, those obtained by using different values of *k* in *[k-means](k-means)*). By this measure, the best clustering will have the largest silhouette score.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"svm\"></a>support vector machine\n",
    "Blah\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"training\" href=\"https://en.wikipedia.org/wiki/Supervised_learning\" >training</a>\n",
    "In supervised learning, the general idea of training a [model](#model) means [optimising](#optimisation) its [parameters](#parameter) so that it maps the [features](#feature) of the [training data](#training_data) to their [responses](#response) as closely as possible. Each machine learning algorithm corresponds to a strategy for adjusting model parameters. The function that is optimised is known as the [loss function](#loss_function).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"training_data\"></a>training data\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"unsupervised_learning\" href=\"https://en.wikipedia.org/wiki/Unsupervised_learning\">unsupervised learning</a>\n",
    "\n",
    "Blah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"vector\"></a>vector\n",
    "Blah\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
